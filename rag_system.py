try:
    # Pinecone 3.x ë²„ì „ (ìƒˆë¡œìš´ ë°©ì‹)
    from pinecone import Pinecone, ServerlessSpec
    PINECONE_VERSION = 3
except ImportError:
    # Pinecone 2.x ë²„ì „ (ì´ì „ ë°©ì‹)
    import pinecone
    PINECONE_VERSION = 2

from openai import OpenAI
from typing import List, Dict
import tiktoken
import time

class RAGSystem:
    def __init__(self, openai_api_key: str, pinecone_api_key: str, pinecone_env: str = "us-east-1"):
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸
        self.openai_client = OpenAI(api_key=openai_api_key)
        
        # ì¸ë±ìŠ¤ ì´ë¦„
        self.index_name = "ad-marketing-textbook"
        
        # Pinecone ë²„ì „ë³„ ì´ˆê¸°í™”
        if PINECONE_VERSION == 3:
            print("ğŸ“Œ Pinecone 3.x ë²„ì „ ì‚¬ìš© ì¤‘...")
            # Pinecone ì´ˆê¸°í™” (ìƒˆë¡œìš´ ë°©ì‹)
            self.pc = Pinecone(api_key=pinecone_api_key)
            
            # Pinecone ì¸ë±ìŠ¤ ì—°ê²° ë˜ëŠ” ìƒì„±
            existing_indexes = [index.name for index in self.pc.list_indexes()]
            
            if self.index_name not in existing_indexes:
                print(f"ì¸ë±ìŠ¤ '{self.index_name}' ìƒì„± ì¤‘...")
                self.pc.create_index(
                    name=self.index_name,
                    dimension=1536,
                    metric="cosine",
                    spec=ServerlessSpec(
                        cloud="aws",
                        region=pinecone_env
                    )
                )
                # ì¸ë±ìŠ¤ ìƒì„± ëŒ€ê¸°
                print("ì¸ë±ìŠ¤ ìƒì„± ëŒ€ê¸° ì¤‘ (ì•½ 10ì´ˆ)...")
                time.sleep(10)
            
            self.index = self.pc.Index(self.index_name)
        else:
            print("ğŸ“Œ Pinecone 2.x ë²„ì „ ì‚¬ìš© ì¤‘...")
            # Pinecone ì´ˆê¸°í™” (ì´ì „ ë°©ì‹)
            pinecone.init(api_key=pinecone_api_key, environment=pinecone_env)
            
            # Pinecone ì¸ë±ìŠ¤ ì—°ê²° ë˜ëŠ” ìƒì„±
            if self.index_name not in pinecone.list_indexes():
                print(f"ì¸ë±ìŠ¤ '{self.index_name}' ìƒì„± ì¤‘...")
                pinecone.create_index(
                    name=self.index_name,
                    dimension=1536,
                    metric="cosine"
                )
                print("ì¸ë±ìŠ¤ ìƒì„± ëŒ€ê¸° ì¤‘ (ì•½ 10ì´ˆ)...")
                time.sleep(10)
            
            self.index = pinecone.Index(self.index_name)
        
        # í† í° ì¹´ìš´í„°
        self.encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
        
    def create_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        response = self.openai_client.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response.data[0].embedding
    
    def search_similar_content(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ êµì¬ ë‚´ìš© ê²€ìƒ‰
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            top_k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            ê´€ë ¨ ë¬¸ì„œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        # ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
        query_vector = self.create_embedding(query)
        
        # Pineconeì—ì„œ ìœ ì‚¬í•œ ë‚´ìš© ê²€ìƒ‰
        results = self.index.query(
            vector=query_vector,
            top_k=top_k,
            include_metadata=True
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        docs = []
        for match in results['matches']:
            docs.append({
                'text': match['metadata'].get('text', ''),
                'source': match['metadata'].get('source', ''),
                'chapter': match['metadata'].get('chapter', ''),
                'score': match['score']
            })
        
        return docs
    
    async def generate_response(self, prompt: str) -> str:
        """
        OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
        
        Args:
            prompt: ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ì „ì²´ í”„ë¡¬í”„íŠ¸
            
        Returns:
            ìƒì„±ëœ ì‘ë‹µ
        """
        response = self.openai_client.chat.completions.create(
            model="gpt-4",  # ë˜ëŠ” "gpt-3.5-turbo"
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë””ì§€í„¸ ê´‘ê³  ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
    
    def add_document(self, text: str, metadata: Dict):
        """
        êµì¬ ë‚´ìš©ì„ ë²¡í„° DBì— ì¶”ê°€
        
        Args:
            text: ì¶”ê°€í•  í…ìŠ¤íŠ¸
            metadata: ë©”íƒ€ë°ì´í„° (source, chapter ë“±)
        """
        # í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        vector = self.create_embedding(text)
        
        # ê³ ìœ  ID ìƒì„± (ASCIIë§Œ í—ˆìš©í•˜ë¯€ë¡œ í•´ì‹œ ì‚¬ìš©)
        import hashlib
        source = metadata.get('source', 'unknown')
        chunk_id = metadata.get('chunk_id', 0)
        
        # í•œê¸€ì„ í¬í•¨í•œ sourceë¥¼ í•´ì‹œë¡œ ë³€í™˜
        source_hash = hashlib.md5(source.encode('utf-8')).hexdigest()[:8]
        doc_id = f"doc_{source_hash}_{chunk_id}"
        
        # ë©”íƒ€ë°ì´í„°ì— ì›ë³¸ í…ìŠ¤íŠ¸ ì¶”ê°€
        metadata['text'] = text
        
        # Pineconeì— ì €ì¥
        self.index.upsert(
            vectors=[(doc_id, vector, metadata)]
        )
    
    def count_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ê³„ì‚°"""
        return len(self.encoding.encode(text))